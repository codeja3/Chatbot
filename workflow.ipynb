{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatMistralAI(model=\"mistral-large-latest\")\n",
    "\n",
    "def call_model(state: MessagesState) -> dict:\n",
    "    updated_messages = model.invoke(state['messages'])\n",
    "    return {\"messages\":updated_messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"model_node\", call_model)\n",
    "workflow.add_edge(START, \"model_node\")\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='My name is Ioannis.', additional_kwargs={}, response_metadata={}, id='010e2182-6e35-4695-8309-cdf7eb5815df'),\n",
       "  AIMessage(content='Hello Ioannis! Nice to meet you. How are you today?', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 10, 'total_tokens': 25, 'completion_tokens': 15}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'}, id='run-d2a9c3db-ec22-40b7-ab57-a4febadc2d40-0', usage_metadata={'input_tokens': 10, 'output_tokens': 15, 'total_tokens': 25})]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat1 = {\"configurable\":{\"thread_id\":1}}\n",
    "app.invoke({\"messages\":\"My name is Ioannis.\"},chat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='My name is Ioannis.', additional_kwargs={}, response_metadata={}, id='010e2182-6e35-4695-8309-cdf7eb5815df'),\n",
       "  AIMessage(content='Hello Ioannis! Nice to meet you. How are you today?', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 10, 'total_tokens': 25, 'completion_tokens': 15}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'}, id='run-d2a9c3db-ec22-40b7-ab57-a4febadc2d40-0', usage_metadata={'input_tokens': 10, 'output_tokens': 15, 'total_tokens': 25}),\n",
       "  HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}, id='35c32a88-732a-49cc-9f37-8a2f8fe019e1'),\n",
       "  AIMessage(content='You told me your name is Ioannis.', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 33, 'total_tokens': 43, 'completion_tokens': 10}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'}, id='run-fe471b6d-5cfc-40ad-ab8d-df282298e1a5-0', usage_metadata={'input_tokens': 33, 'output_tokens': 10, 'total_tokens': 43})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"messages\":\"What is my name?\"},chat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = app.invoke(None, chat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "My name is Ioannis.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Ioannis! Nice to meet you. How are you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You told me your name is Ioannis.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[message.pretty_print() for message in output['messages']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat2 = {\"configurable\":{\"thread_id\": 2}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm an artificial intelligence and I don't have real-time personal information about you. Unless you've shared your name in our conversation, I wouldn't know it. If you'd like me to use a specific name when addressing you, please let me know!\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"messages\":\"What is my name?\"}, chat2)['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(chat_id: int):\n",
    "\n",
    "    config = {\"configurable\":{\"thread_id\": chat_id}}\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "\n",
    "        if user_input in [\"exit\", \"quit\"]:\n",
    "            print(\"AI: See you later!\")\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "           output = app.invoke({\"messages\":user_input}, config)\n",
    "           print(\"AI:\", output['messages'][-1].content, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Hello my name is Ioannis. How are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hello Ioannis! I'm functioning well, thank you. How about you? How's your day going?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  so far so good. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: That's great to hear! What do you have planned for the rest of the day? Anything interesting?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  I'm planning to model data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: That sounds like a productive plan! What kind of data are you working with, and what tools or programming languages are you using for modeling? I might be able to provide some tips or resources if you need them. Here are a few common tools and languages for data modeling:\n",
      "\n",
      "* Languages: Python (Pandas, NumPy, SciKit-learn), R (tidyverse, caret), SQL\n",
      "* Tools: Jupyter Notebooks, RStudio, Excel, Power BI, Tableau\n",
      "* Databases: MySQL, PostgreSQL, MongoDB\n",
      "* Cloud Platforms: Google Cloud Platform, Amazon Web Services, Microsoft Azure\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: See you later!\n"
     ]
    }
   ],
   "source": [
    "chatbot(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(chat_id: int):\n",
    "\n",
    "    config = {\"configurable\":{\"thread_id\": chat_id}}\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "\n",
    "        if user_input in [\"exit\", \"quit\"]:\n",
    "            print(\"AI: See you later!\")\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            print(\"AI:\", end=\"\")\n",
    "            for chunk,metadata in app.stream({\"messages\":user_input}, \n",
    "                               config,\n",
    "                              stream_mode=\"messages\"):\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what is an LLM?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:LLM stands for **Large Language Model**. It's a type of artificial intelligence model designed to understand and generate human language based on prompts it receives. Here are some key points about LLMs:\n",
      "\n",
      "1. **Size**: The term \"large\" refers to the number of parameters the model has. Parameters are what the model learns from the training data. LLMs typically have billions of parameters.\n",
      "\n",
      "2. **Training**: LLMs are trained on vast amounts of text data from the internet. This helps them understand and generate text in a way that mimics human language.\n",
      "\n",
      "3. **Versatility**: LLMs can perform a wide range of tasks, such as:\n",
      "   - Answering questions and providing explanations.\n",
      "   - Generating text, from poems to code.\n",
      "   - Translating languages.\n",
      "   - Summarizing text.\n",
      "   - And much more.\n",
      "\n",
      "4. **Limitations**: While LLMs can generate impressive results, they don't have personal experiences, feelings, or consciousness. They also don't have real-time information, as their knowledge cutoff is determined by the data they were trained on.\n",
      "\n",
      "5. **Examples**: Some examples of LLMs include me (the model you're currently interacting with), as well as others like LaMDA, PaLM, and those used in services like GitHub's Copilot.\n",
      "\n",
      "In essence, LLMs are a significant part of modern AI and are used in a variety of applications, from chatbots to code generation tools.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: See you later!\n"
     ]
    }
   ],
   "source": [
    "chatbot(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:chatbot]",
   "language": "python",
   "name": "conda-env-chatbot-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
